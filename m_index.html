<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for Neurips 2024">
  <meta property="og:title" content="Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization" />
  <meta property="og:description" content="Project page for Neurips 2024" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/framework.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization">
  <meta name="twitter:description" content="Project page for Neurips 2024">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/framework.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="easy to hard, difficulty levels, large language models, weak to strong">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization</title>
  <link rel="icon" type="image/x-icon" href="static/images/e2h.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/all.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <!--<script defer src="static/js/fontawesome.all.min.js"></script>-->
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!--
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  -->
  <script type="text/javascript" src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="text-content" style="text-align: left; margin-bottom: 10px;">
        <p><a href="index.html" target="_self">[PC]</a> <a href="m_index.html" target="_self">[Mobile]</a>
        </p>
        </div>
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title"><img src="static/images/e2h.ico" width="30px"> Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="http://www.cs.umd.edu/~mcding/" target="_blank">Mucong Ding</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://deng-chenghao.com/" target="_blank">Chenghao Deng</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Jocelyn Choo</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Zichu Wu</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/bits-pilani.ac.in/aakriti/home" target="_blank">Aakriti Agarawal</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://cs.umd.edu/~avi1" target="_blank">Avi Schwarzschild</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://tianyizhou.github.io/" target="_blank">Tianyi Zhou</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.umd.edu/~tomg/" target="_blank">Tom Goldstein</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://hunch.net/~jl" target="_blank">John Langford</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima Anandkumar</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="https://furong-huang.com" target="_blank">Furong Huang</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors"></div>
              <span class="author-block">University of Maryland, College Park<sup>1</sup>
                &nbsp;&nbsp;&nbsp;&nbsp;University of Waterloo<sup>2</sup>
                &nbsp;&nbsp;&nbsp;&nbsp;Carnegie Mellon University<sup>3</sup>
                &nbsp;&nbsp;&nbsp;&nbsp;Microsoft<sup>4</sup>
                &nbsp;&nbsp;&nbsp;&nbsp;California Institute of Technology<sup>5</sup>
                <br>NeurIPS 2024 Track Datasets and Benchmarks
              </span>
              <span class="eql-cntrb"><small><small><small><br><sup>*</sup>Equal
                      Contribution</small></small></small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2409.18433" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <!--
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>
                  -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/umd-huang-lab/Easy2Hard-Bench.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-brands fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Twitter link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-brands fa-x-twitter"></i>
                    </span>
                    <span>X (twitter)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.18433" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Hugging Face Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/collections/furonghuang-lab/easy2hard-bench-666a0d26f3932ecb92c112c2" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-solid fa-face-smiling-hands"></i>
                    </span>
                    <span>Hugging Face</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!--<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>-->
  <!-- End teaser video -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">      
        <!-- First Image with adjusted size and centered -->
        <div style="margin-bottom: 40px; text-align: center;"> <!-- Adjust the margin as needed -->
          <img src="static/images/hf_data.png" alt="Description of First Image" style="width: 900px; display: block; margin: auto;"/> <!-- Adjust width as needed -->
          <!-- Caption with constrained width -->
          <div style="max-width: 850px; margin: auto;"> <!-- Adjust max-width as needed -->
            <h2 class="subtitle has-text-centered">
              <small>
              Easy2Hard-Bench (E2H-Bench): a collection of LLM datasets spanning a wide range of domains featuring standardized difficulty labels for individual problems.
              </small>
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Despite the abundance of datasets available for assessing large language models (LLMs), the scarcity of continuous and reliable difficulty labels for individual data points, in most cases, curtails their capacity to benchmark model generalization performance across different levels of complexity. 
              Addressing this limitation, we present Easy2Hard, an innovative collection of 6 benchmark datasets featuring standardized difficulty labels spanning a wide range of domains, such as mathematics and programming problems, chess puzzles, and reasoning questions, providing a much-needed tool for those in demand of a dataset with varying degrees of difficulty for LLM assessment. 
              We estimate the difficulty of individual problems by leveraging the performance data of many human subjects and LLMs on prominent leaderboards. 
              Harnessing the rich human performance data, we employ widely recognized difficulty ranking systems, including the Item Response Theory (IRT) and Glicko-2 models, to uniformly assign difficulty scores to problems. 
              The Easy2Hard datasets distinguish themselves from previous collections by incorporating a significantly higher proportion of challenging problems, presenting a novel and demanding test for state-of-the-art LLMs. 
              Through extensive experiments conducted with six state-of-the-art LLMs on the Easy2Hard datasets, we offer valuable insights into their performance and generalization capabilities across varying degrees of difficulty, setting the stage for future research in LLM generalization.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Benchmark Overview -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="title is-4">Benchmark Overview</h3>

        <div class="text-context" style="text-align: left; margin-bottom: 30px;">
          <p>
            The Easy2Hard-Bench spans six distinct domains, including mathematics, programming, chess, and various reasoning tasks. 
            These diverse tasks encompass a broad spectrum of prevalent cognitive challenges for LLMs.
            The problems in each dataset of Easy2Hard-Bench are annotated with a numerical value as difficulty estimation.
          </p>
        </div>

        <div style="margin-bottom: 40px; text-align: center;">
          <div class="item item-video1" style="text-align: center;">
            <video poster="" id="video1" width="100%" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/composition.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="text-context" style="text-align: left; margin-bottom: 30px;">
          <p>
            We find data sources of problems with abundant publicly available human performance statistics, which serve as a robust basis for difficulty estimation.
            For those datasets on which human performance is inaccessible in large scale, we use the evaluation results by LLMs from <i>Open LLM Leadearboad</i> as surrogate.
          </p>
        </div>

        <div class="item" style="margin-top: 30px; margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/overview.png" alt="overview0"
            style="width: 90%; display: block; margin: auto;" /> <!-- Adjust width as needed -->
        </div>
      </div>
    </div>
  </section>
  <!-- Benchmark Overview -->

  <!-- Difficulty Estimation -->
  <section class="hero teaser is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h3 class="title is-4">Difficulty Estimation</h3>

        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p>
            The difficulty of problems is estimated using continuous values, employing advanced statistical models such as Glicko-2 and Item Response Theory (IRT). 
            This methodology utilizes abundant real-world performance results from humans and leaderboard data from LLMs, providing a clearer insight into the difficulty structure of each dataset.
          </p>
        </div>

        <div style="margin-bottom: 80px; text-align: center;">
          <div class="item item-video1" style="text-align: center;">
            <video poster="" id="video1" width="100%" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/process.mp4" type="video/mp4">
            </video>
          </div>
        </div>

        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p>The plots of difficulty distribution in <b>E2H</b> 
            datasets showcase that the problems within each domain cover a wide range of difficulties.
            For <b>E2H-AMC</b> and <b>E2H-Codeforces</b>, we also draw the difficulty distribution of overlappping parts with the existing benchmarks <i>MATH</i> and <i>APPS</i>, repectvely.
            The comparisons verify that our datasets include more challenging problems.
          </p>
        </div>

        <div class="item" style="margin-top: 30px; margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/hf_distribution.png" alt="overview1"
            style="width: 80%; display: block; margin: auto;" /> <!-- Adjust width as needed -->
        </div>

      </div>
    </div>
  </section>
  <!-- Difficulty Estimation -->  

  <!-- Benchmarking SoTA LLMs -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h3 class="title is-4">Benchmarking SoTA LLMs</h3>
        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p>In light of the novel and challenging problems presented in our Easy2Hard-Bench, we select 6 SoTA LLMs for evaluation.
            We begin by presenting the performance of LLMs on all Easy2Hard-Bench datasets, segmented into easy, medium, and hard difficulty levels.
            It is evident that performance notably decreases as difficulty increases, validating the effectiveness of our difficulty estimations.
            The newly curated datasets (<b>E2H-AMC</b>, <b>E2H-Codeforces</b>, <b>E2H-Lichess</b>) are much more challenging than the pre-existing ones, because they extend the difficulty range greatly compared to existing selections.
          </p>
        </div>

        <div class="item" style="margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/plot/figure4.png" alt="profile1" style="width: 100%; display: block; margin: auto;" />
          <!-- Adjust width as needed -->
        </div>

        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p> Furthermore, we plot and analyze model behavior against increasing difficulty levels for each dataset.
            As evaluation difficulty increases, most models show monotonic decreasing accuracies, validating the correctness of provided difficulty ratings. 
            While performance generally declines with difficulty, the extent of this decline varies significantly among models and datasets.
          </p>
        </div>

        <div class="item" style="margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/plot/figure5.png" alt="profile2" style="width: 100%; display: block; margin: auto;" />
          <!-- Adjust width as needed -->
        </div>
      </div>
    </div>
  </section>

  <!-- Profiling Easy2Hard Generalizations -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h3 class="title is-4">Profiling Easy2Hard Generalizations</h3>
        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p>
            Instead of only assessing the static behavior of specific checkpoints, Easy2Hard-Bench allows for fine-grained profiling of LLMs as they generalize across various training and evaluation difficulties. 
            This also caters to the need to simulate challenging problems like weak-to-strong generalization.
            To our best knowledge, Easy2Hard-Bench is the first to deliver detailed easy-to-hard generalization results across continuous, wide-range of difficulties on LLMs.
          </p>
        </div>

        <div class="item" style="margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/plot/figure6.png" alt="generalize" style="width: 100%; display: block; margin: auto;" />
          <!-- Adjust width as needed -->
        </div>

        <div class="text-content" style="text-align: left; margin-bottom: 30px;">
          <p> 
            In our preliminary experimental exploration, we focus on Supervised Finetuning (SFT) with relatively smaller LLMs, while deferring more specialized finetuning frameworks for future studies.
            LLMs are trained on subsets of training splits of varying difficulty (y-axis) via Supervised Fine-Tuning (SFT) and were evaluated across all evaluation difficulties (x-axis). 
            The color gradient represents the performance difference relative to models trained on randomly selected difficulties of same sizes.
            We observe generalization benefits when training and evaluation difficulties are similar, and training on more challenging samples poses increased generalization difficulties.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper poster -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>
        <div class="item" style="margin-bottom: 30px; text-align: center;"> <!-- Centering the content -->
          <!-- Second image resized -->
          <img src="static/images/poster.png" alt="poster" style="width: 100%; display: block; margin: auto;" />
          <!-- Adjust width as needed -->
        </div>
      </div>
    </div>
  </section>
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section is-light" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
          ding2024easyhardbench,
          title={Easy2Hard-Bench: Standardized Difficulty Labels for Profiling {LLM} Performance and Generalization},
          author={Mucong Ding and Chenghao Deng and Jocelyn Choo and Zichu Wu and Aakriti Agrawal and Avi Schwarzschild and Tianyi Zhou and Tom Goldstein and John Langford and Anima Anandkumar and Furong Huang},
          booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
          year={2024},
          url={https://openreview.net/forum?id=iNB4uoFQJb}
        }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>